{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(style='ticks', palette='Set2')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from __future__ import division\n",
    "import sys, re\n",
    "from scipy.optimize.optimize import fmin_cg, fmin_bfgs, fmin\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import loadtxt, where, zeros, e, array, log, ones, mean, where\n",
    "from pylab import scatter, show, legend, xlabel, ylabel, plot\n",
    "from scipy.optimize import fmin_bfgs\n",
    "import math \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_func(theta, x):\n",
    "    return float(1) / (1 + math.e**(-x.dot(theta)))\n",
    "def log_gradient(theta, x, y):\n",
    "    first_calc = logistic_func(theta, x) - np.squeeze(y)\n",
    "    final_calc = first_calc.T.dot(x)\n",
    "    return final_calc\n",
    "def cost_func(theta, x, y):\n",
    "    log_func_v = logistic_func(theta,x)\n",
    "    y = np.squeeze(y)\n",
    "    step1 = y * np.log(log_func_v)\n",
    "    step2 = (1-y) * np.log(1 - log_func_v)\n",
    "    final = -step1 - step2\n",
    "    return np.mean(final)\n",
    "def grad_desc(theta_values, X, y, lr=.001, converge_change=.001):\n",
    "    #normalize\n",
    "    X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "    #setup cost iter\n",
    "    cost_iter = []\n",
    "    cost = cost_func(theta_values, X, y)\n",
    "    cost_iter.append([0, cost])\n",
    "    change_cost = 1\n",
    "    i = 1\n",
    "    while(change_cost > converge_change):\n",
    "        old_cost = cost\n",
    "        theta_values = theta_values - (lr * log_gradient(theta_values, X, y))\n",
    "        cost = cost_func(theta_values, X, y)\n",
    "        cost_iter.append([i, cost])\n",
    "        change_cost = old_cost - cost\n",
    "        i+=1\n",
    "    return theta_values, np.array(cost_iter)\n",
    "def pred_values(theta, X, hard=True):\n",
    "    #normalize\n",
    "    X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "    pred_prob = logistic_func(theta, X)\n",
    "    pred_value = np.where(pred_prob >= .5, 1, 0)\n",
    "    if hard:\n",
    "        return pred_value\n",
    "    return pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"C:\\Users\\Niku\\Documents\\dataset\\dataset_40_attributes5.xlsx\")\n",
    "#X = data[['householdsize', 'medIncome', 'PctSpeakEnglOnly', 'PctPersDenseHous']]\n",
    "X = data[['householdsize', 'medIncome']]\n",
    "#X = data\n",
    "y = data['Category']\n",
    "pos = where(y == 1)\n",
    "neg = where(y == 0)\n",
    "X = np.matrix(X)\n",
    "y = np.matrix(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape = X.shape[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
